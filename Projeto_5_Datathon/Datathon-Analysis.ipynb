{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desabilitando warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datathon - Sistema de recomendação de noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prmeiramente estou fazendo o download do arquivo. Estou usando o stream e salvando o arquivo incementalmente, pois o arquivo é relativamente grande e possui mais de 1 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = r'https://drive.usercontent.google.com/download?id=13rvnyK5PJADJQgYe-VbdXb7PpLPj7lPr&export=download&authuser=0&confirm=t&uuid=02f630ab-0d33-489e-ae09-45facc58edfa&at=APvzH3qdyuGKBM5eXLv9nq2BIPb3%3A1736166348726'\n",
    "\n",
    "response = requests.get(URL, stream=True)\n",
    "\n",
    "with open('data.zip', 'wb') as file:\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            file.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraindo o conteudo do arquivo para uma pasta de dados para que possamos analizar o seu conteúdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "\n",
    "os.remove('data.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os arquivos foram baixados, podemos começar a verificar os dados baixados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conferindo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>userType</th>\n",
       "      <th>historySize</th>\n",
       "      <th>history</th>\n",
       "      <th>timestampHistory</th>\n",
       "      <th>numberOfClicksHistory</th>\n",
       "      <th>timeOnPageHistory</th>\n",
       "      <th>scrollPercentageHistory</th>\n",
       "      <th>pageVisitsCountHistory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f98d1132f60d46883ce49583257104d15ce723b3bbda21...</td>\n",
       "      <td>Non-Logged</td>\n",
       "      <td>3</td>\n",
       "      <td>c8aab885-433d-4e46-8066-479f40ba7fb2, 68d2039c...</td>\n",
       "      <td>1657146417045, 1657146605778, 1657146698738</td>\n",
       "      <td>76, 38, 41</td>\n",
       "      <td>20380, 21184, 35438</td>\n",
       "      <td>50.3, 18.18, 16.46</td>\n",
       "      <td>2, 1, 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              userId    userType  historySize  \\\n",
       "0  f98d1132f60d46883ce49583257104d15ce723b3bbda21...  Non-Logged            3   \n",
       "\n",
       "                                             history  \\\n",
       "0  c8aab885-433d-4e46-8066-479f40ba7fb2, 68d2039c...   \n",
       "\n",
       "                              timestampHistory numberOfClicksHistory  \\\n",
       "0  1657146417045, 1657146605778, 1657146698738            76, 38, 41   \n",
       "\n",
       "     timeOnPageHistory scrollPercentageHistory pageVisitsCountHistory  \n",
       "0  20380, 21184, 35438      50.3, 18.18, 16.46                2, 1, 1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivos = [ f'./data/files/treino/treino_parte{n}.csv' for n in range(1, 7) ]\n",
    "dfs = [ pd.read_csv(arquivo) for arquivo in arquivos ]\n",
    "df_treino = pd.concat(dfs)\n",
    "\n",
    "del arquivos, dfs\n",
    "\n",
    "df_treino = df_treino.drop(columns=['timestampHistory_new'])\n",
    "\n",
    "df_treino.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses são os dados de acesso às matérias do G1, nesse dataframe temos os dados de atividade dos usuários da plataforma de notícias, além de tempo de leitura, percentual de rolagem da pagina, entre outros.\n",
    "\n",
    "Cada linha apresenta os dados de 1 unico usuário, tendo as informações de acesso em um formato que dificulta a utilização. Alguns ajustes na formatação do arquivo podem facilitar o processo de análise dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 577942 entries, 0 to 77941\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   userId                   577942 non-null  object\n",
      " 1   userType                 577942 non-null  object\n",
      " 2   historySize              577942 non-null  int64 \n",
      " 3   history                  577942 non-null  object\n",
      " 4   timestampHistory         577942 non-null  object\n",
      " 5   numberOfClicksHistory    577942 non-null  object\n",
      " 6   timeOnPageHistory        577942 non-null  object\n",
      " 7   scrollPercentageHistory  577942 non-null  object\n",
      " 8   pageVisitsCountHistory   577942 non-null  object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 44.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>url</th>\n",
       "      <th>issued</th>\n",
       "      <th>modified</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13db0ab1-eea2-4603-84c4-f40a876c7400</td>\n",
       "      <td>http://g1.globo.com/am/amazonas/noticia/2022/0...</td>\n",
       "      <td>2022-06-18 20:37:45+00:00</td>\n",
       "      <td>2023-04-15 00:02:08+00:00</td>\n",
       "      <td>Caso Bruno e Dom: 3º suspeito tem prisão tempo...</td>\n",
       "      <td>Após audiência de custódia, a Justiça do Amazo...</td>\n",
       "      <td>Jeferson da Silva Lima foi escoltado por agent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   page  \\\n",
       "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
       "\n",
       "                      issued                   modified  \\\n",
       "0  2022-06-18 20:37:45+00:00  2023-04-15 00:02:08+00:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Caso Bruno e Dom: 3º suspeito tem prisão tempo...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Após audiência de custódia, a Justiça do Amazo...   \n",
       "\n",
       "                                             caption  \n",
       "0  Jeferson da Silva Lima foi escoltado por agent...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivos = [ f'./data/itens/itens/itens-parte{n}.csv' for n in range(1, 4) ]\n",
    "dfs = [ pd.read_csv(arquivo) for arquivo in arquivos ]\n",
    "df_itens = pd.concat(dfs)\n",
    "\n",
    "del arquivos, dfs\n",
    "\n",
    "df_itens.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse arquivo contém as informações das matérias disponíveis no portal G1. Essas informações podem ser relevantes para buscar as correlações entre as matérias e enriquecer nosso sistema de recomendação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise e normalização de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente quero transformar os dados tanto em formato em que estão estruturados, quanto em relação à tipagem. Essas transformações devem facilitar os trabalhos futuros de manipulação e visualização desses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/files/treino/long_format.csv'):    \n",
    "    colunas_separadas_por_virgula = ['history', 'timestampHistory', 'numberOfClicksHistory', 'timeOnPageHistory', 'scrollPercentageHistory', 'pageVisitsCountHistory']\n",
    "\n",
    "    for coluna in colunas_separadas_por_virgula:\n",
    "        df_treino[coluna] = df_treino[coluna].str.split(',')\n",
    "\n",
    "    df_treino = df_treino.explode(colunas_separadas_por_virgula)\n",
    "\n",
    "    df_treino.to_csv(r'data/files/treino/long_format.csv', index=False)\n",
    "\n",
    "else:\n",
    "    df_treino = pd.read_csv(r'data/files/treino/long_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>userType</th>\n",
       "      <th>historySize</th>\n",
       "      <th>history</th>\n",
       "      <th>timestampHistory</th>\n",
       "      <th>numberOfClicksHistory</th>\n",
       "      <th>timeOnPageHistory</th>\n",
       "      <th>scrollPercentageHistory</th>\n",
       "      <th>pageVisitsCountHistory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f98d1132f60d46883ce49583257104d15ce723b3bbda21...</td>\n",
       "      <td>Non-Logged</td>\n",
       "      <td>3</td>\n",
       "      <td>c8aab885-433d-4e46-8066-479f40ba7fb2</td>\n",
       "      <td>1657146417045</td>\n",
       "      <td>76</td>\n",
       "      <td>20380</td>\n",
       "      <td>50.30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f98d1132f60d46883ce49583257104d15ce723b3bbda21...</td>\n",
       "      <td>Non-Logged</td>\n",
       "      <td>3</td>\n",
       "      <td>68d2039c-c9aa-456c-ac33-9b2e8677fba7</td>\n",
       "      <td>1657146605778</td>\n",
       "      <td>38</td>\n",
       "      <td>21184</td>\n",
       "      <td>18.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f98d1132f60d46883ce49583257104d15ce723b3bbda21...</td>\n",
       "      <td>Non-Logged</td>\n",
       "      <td>3</td>\n",
       "      <td>13e423ce-1d69-4c78-bc18-e8c8f7271964</td>\n",
       "      <td>1657146698738</td>\n",
       "      <td>41</td>\n",
       "      <td>35438</td>\n",
       "      <td>16.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              userId    userType  historySize  \\\n",
       "0  f98d1132f60d46883ce49583257104d15ce723b3bbda21...  Non-Logged            3   \n",
       "1  f98d1132f60d46883ce49583257104d15ce723b3bbda21...  Non-Logged            3   \n",
       "2  f98d1132f60d46883ce49583257104d15ce723b3bbda21...  Non-Logged            3   \n",
       "\n",
       "                                 history  timestampHistory  \\\n",
       "0   c8aab885-433d-4e46-8066-479f40ba7fb2     1657146417045   \n",
       "1   68d2039c-c9aa-456c-ac33-9b2e8677fba7     1657146605778   \n",
       "2   13e423ce-1d69-4c78-bc18-e8c8f7271964     1657146698738   \n",
       "\n",
       "   numberOfClicksHistory  timeOnPageHistory  scrollPercentageHistory  \\\n",
       "0                     76              20380                    50.30   \n",
       "1                     38              21184                    18.18   \n",
       "2                     41              35438                    16.46   \n",
       "\n",
       "   pageVisitsCountHistory  \n",
       "0                       2  \n",
       "1                       1  \n",
       "2                       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8123951 entries, 0 to 8123950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   userId                   object \n",
      " 1   userType                 object \n",
      " 2   historySize              int64  \n",
      " 3   history                  object \n",
      " 4   timestampHistory         int64  \n",
      " 5   numberOfClicksHistory    int64  \n",
      " 6   timeOnPageHistory        int64  \n",
      " 7   scrollPercentageHistory  float64\n",
      " 8   pageVisitsCountHistory   int64  \n",
      "dtypes: float64(1), int64(5), object(3)\n",
      "memory usage: 557.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino['userType'] = df_treino['userType'].astype('category')\n",
    "df_treino['historySize'] = df_treino['historySize'].astype('int')\n",
    "df_treino['timestampHistory'] = pd.to_datetime(df_treino['timestampHistory'], unit='ms')\n",
    "df_treino['numberOfClicksHistory'] = df_treino['numberOfClicksHistory'].astype('int')\n",
    "df_treino['timeOnPageHistory'] = df_treino['timeOnPageHistory'].astype('int')\n",
    "df_treino['scrollPercentageHistory'] = df_treino['scrollPercentageHistory'].astype('float')\n",
    "df_treino['pageVisitsCountHistory'] = df_treino['pageVisitsCountHistory'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8123951 entries, 0 to 8123950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   userId                   object        \n",
      " 1   userType                 category      \n",
      " 2   historySize              int64         \n",
      " 3   history                  object        \n",
      " 4   timestampHistory         datetime64[ns]\n",
      " 5   numberOfClicksHistory    int64         \n",
      " 6   timeOnPageHistory        int64         \n",
      " 7   scrollPercentageHistory  float64       \n",
      " 8   pageVisitsCountHistory   int64         \n",
      "dtypes: category(1), datetime64[ns](1), float64(1), int64(4), object(2)\n",
      "memory usage: 503.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>userType</th>\n",
       "      <th>historySize</th>\n",
       "      <th>history</th>\n",
       "      <th>timestampHistory</th>\n",
       "      <th>numberOfClicksHistory</th>\n",
       "      <th>timeOnPageHistory</th>\n",
       "      <th>scrollPercentageHistory</th>\n",
       "      <th>pageVisitsCountHistory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f98d1132f60d46883ce49583257104d15ce723b3bbda21...</td>\n",
       "      <td>Non-Logged</td>\n",
       "      <td>3</td>\n",
       "      <td>c8aab885-433d-4e46-8066-479f40ba7fb2</td>\n",
       "      <td>2022-07-06 22:26:57.045</td>\n",
       "      <td>76</td>\n",
       "      <td>20380</td>\n",
       "      <td>50.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              userId    userType  historySize  \\\n",
       "0  f98d1132f60d46883ce49583257104d15ce723b3bbda21...  Non-Logged            3   \n",
       "\n",
       "                                history        timestampHistory  \\\n",
       "0  c8aab885-433d-4e46-8066-479f40ba7fb2 2022-07-06 22:26:57.045   \n",
       "\n",
       "   numberOfClicksHistory  timeOnPageHistory  scrollPercentageHistory  \\\n",
       "0                     76              20380                     50.3   \n",
       "\n",
       "   pageVisitsCountHistory  \n",
       "0                       2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(r'data/itens/itens/long_format.csv'):\n",
    "    df_itens.to_csv(r'data/itens/itens/long_format.csv', index=False)\n",
    "\n",
    "else:\n",
    "    df_itens = pd.read_csv(r'data/itens/itens/long_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>url</th>\n",
       "      <th>issued</th>\n",
       "      <th>modified</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13db0ab1-eea2-4603-84c4-f40a876c7400</td>\n",
       "      <td>http://g1.globo.com/am/amazonas/noticia/2022/0...</td>\n",
       "      <td>2022-06-18 20:37:45+00:00</td>\n",
       "      <td>2023-04-15 00:02:08+00:00</td>\n",
       "      <td>Caso Bruno e Dom: 3º suspeito tem prisão tempo...</td>\n",
       "      <td>Após audiência de custódia, a Justiça do Amazo...</td>\n",
       "      <td>Jeferson da Silva Lima foi escoltado por agent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   page  \\\n",
       "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
       "\n",
       "                      issued                   modified  \\\n",
       "0  2022-06-18 20:37:45+00:00  2023-04-15 00:02:08+00:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Caso Bruno e Dom: 3º suspeito tem prisão tempo...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Após audiência de custódia, a Justiça do Amazo...   \n",
       "\n",
       "                                             caption  \n",
       "0  Jeferson da Silva Lima foi escoltado por agent...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_itens.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analise de itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso Bruno e Dom: 3º suspeito tem prisão temporária decretada pela Justiça do AM\n",
      "-----------------------------------\n",
      "Jeferson da Silva Lima foi escoltado por agentes da Polícia Federal ao Fórum de Justiça do município para a audiência de custódia\n",
      "-----------------------------------\n",
      "Após audiência de custódia, a Justiça do Amazonas decretou, na tarde deste sábado (18), a prisão temporária,  por 30 dias, de Jeferson da Silva Lima, conhecido como \"Pelado da Dinha\". Ele teve participação direta na morte do indigenista Bruno Pereira e do jornalista inglês Dom Phillips, aponta as investigações. \n",
      "\"Pelado da Dinha\" foi considerado foragido na noite de sexta-feira (17) após ter o mandado de prisão expedido e não ser localizado pelas autoridades. Ele se entregou na delegacia de Atalaia do Norte, a 1.136 quilômetros de Manaus, nas primeiras horas da manhã deste sábado, onde foi ouvido pelo delegado Alex Perez Timóteo. \n",
      "\"Pelado da Dinha\" foi considerado foragido na noite de sexta-feira (17) após ter o mandado de prisão expedido \n",
      "Rôney Elias/Rede Amazônica \n",
      "Durante a tarde, Jeferson foi escoltado por agentes da Polícia Federal ao Fórum de Justiça do município para a audiência de custódia e teve a prisão temporária decretada. \n",
      "Perícia confirma identificação dos restos mortais de Bruno Pereira\n",
      "O delegado afirmou que, segundo as investigações, Jeferson tem participação direta no caso, desde a emboscada até a ocultação dos corpos.  \"Conforme todas as provas, todos os depoimentos colhidos até o momento, ele estava na cena do crime e participou ativamente do duplo homicídio ocorrido\", disse.\n",
      "Assim como os outros dois presos, o prazo de 30 dias da prisão temporária de Jeferson pode ser prorrogado por mais 30. O processo tramita sob Segredo de Justiça.\n",
      "A audiência de custódia foi realizada de forma híbrida- com a juíza, o investigado e o promotor de Justiça\n",
      "Tjam \n",
      "Irmãos presos\n",
      "No dia 9 de junho, a Justiça decretou a prisão temporária de Amarildo da Costa de Oliveira, conhecido como \"Pelado\", que confessou o crime no dia 15, um dia após o irmão Oseney da Costa de Oliveira, conhecido como \"Dos Santos\", ter sido preso.\n",
      "Também no dia 15 de junho, a Justiça decretou a prisão temporária de Oseney. Os três suspeitos seguem detidos na carceragem da 50ª Delegacia Interativa de Polícia (DIP) de Atalaia de Norte. \n",
      "Bruno e Dom foram mortos a tiros \n",
      "Um laudo de peritos da Polícia Federal confirmou, neste sábado (18), que o indigenista Bruno Araújo Pereira e o jornalista inglês Dom Phillips foram mortos a tiros, com munição de caça. \n",
      "Segundo a análise, Bruno foi atingido por três disparos, dois no tórax e um na cabeça. Já Dom foi baleado uma vez, no tórax.\n",
      "LEIA TAMBÉM: \n",
      "PF confirma que restos mortais encontrados na Amazônia são do indigenista Bruno Pereira\n",
      "Perícia da PF confirma que restos mortais encontrados na Amazônia são do jornalista Dom Phillips\n",
      "Buscas pela embarcação\n",
      "Neste sábado (18) continuam as buscas pela embarcação que transportava Bruno Pereira e Dom Phillips. Na sexta-feira (17), as ações das forças de segurança encerraram no final da tarde.\n",
      "A região onde as buscas se concentram foi apontada por Amarildo da Costa Oliveira. Ele também indicou à polícia o local onde a embarcação foi afundada e a área onde os corpos das vítimas foram ocultados.\n",
      "Motivação\n",
      "A motivação do crime ainda é incerta, mas a polícia apura se há relação com a atividade de pesca ilegal e tráfico de drogas na região. Segunda maior terra indígena do país, o Vale do Javari é palco de conflitos típicos da Amazônia: desmatamento e avanço do garimpo.\n",
      "Aras e procuradores vão ao AM\n",
      "O procurador-geral da República, Augusto Aras, e membros do Ministério Público Federal viajam a Tabatinga, no Amazonas, neste domingo (19).\n",
      " O grupo deve participar de reuniões sobre a insegurança na Amazônia e, também, acompanhar os desdobramentos do assassinato do indigenista Bruno Pereira e do jornalista britânico Dom Phillips.\n",
      "(CORREÇÃO: o Jornal Nacional errou no dia 18 de junho de 2022 ao exibir a imagem de um outro homem, de nome parecido, como se fosse Jeferson da Silva Lima, suspeito de participar do assassinato de Bruno Pereira e Dom Phillips no Vale do Javari, no Amazonas. O suspeito Jeferson da Silva Lima é este homem que você na foto abaixo. O Jornal Nacional pede desculpas a você e, em especial, ao homem cuja foto tinha sido exibida erroneamente.)\n",
      "Jeferson da Silva Lima, suspeito de participar do assassinato de Bruno Pereira e Dom Phillips no Vale do Javari, no Amazonas\n",
      "Jornal Nacional\n",
      "Os vídeos mais assistidos do Amazonas:\n"
     ]
    }
   ],
   "source": [
    "print(df_itens.iloc[0]['title'])\n",
    "print('-----------------------------------')\n",
    "print(df_itens.iloc[0]['caption'])\n",
    "print('-----------------------------------')\n",
    "print(df_itens.iloc[0]['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primeiramente quero testar a possibilidade de utilizar tags para simplificar a busca de matérias com conteúdos similates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "pt_stopwords = list(stopwords.words('portuguese'))\n",
    "\n",
    "def teste_tags(feature:str, top_n=25):\n",
    "    vectorizer = TfidfVectorizer(stop_words=pt_stopwords)\n",
    "    X = vectorizer.fit_transform(df_itens[feature])\n",
    "\n",
    "    termos = vectorizer.get_feature_names_out()\n",
    "\n",
    "    def obter_tags(indice_texto, top_n=top_n):\n",
    "        tfidf_scores = X[indice_texto].toarray().flatten()\n",
    "        indices = tfidf_scores.argsort()[-top_n:][::-1]\n",
    "        return [termos[i] for i in indices]\n",
    "        \n",
    "\n",
    "    for i, texto in enumerate(df_itens[feature][:5]):\n",
    "        print(f\"Texto: {texto[:80]}\")\n",
    "        print(f\"Tags: {' '.join(obter_tags(i))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a à ao aos aquela aquelas aquele aqueles aquilo as às até com como da das de dela delas dele deles depois do dos e é ela elas ele eles em entre era eram éramos essa essas esse esses esta está estamos estão estar estas estava estavam estávamos este esteja estejam estejamos estes esteve estive estivemos estiver estivera estiveram estivéramos estiverem estivermos estivesse estivessem estivéssemos estou eu foi fomos for fora foram fôramos forem formos fosse fossem fôssemos fui há haja hajam hajamos hão havemos haver hei houve houvemos houver houvera houverá houveram houvéramos houverão houverei houverem houveremos houveria houveriam houveríamos houvermos houvesse houvessem houvéssemos isso isto já lhe lhes mais mas me mesmo meu meus minha minhas muito na não nas nem no nos nós nossa nossas nosso nossos num numa o os ou para pela pelas pelo pelos por qual quando que quem são se seja sejam sejamos sem ser será serão serei seremos seria seriam seríamos seu seus só somos sou sua suas também te tem tém temos tenha tenham tenhamos tenho terá terão terei teremos teria teriam teríamos teu teus teve tinha tinham tínhamos tive tivemos tiver tivera tiveram tivéramos tiverem tivermos tivesse tivessem tivéssemos tu tua tuas um uma você vocês vos'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(pt_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopwords** são palavras que podem ser desconsideradas na análise. Por hora estamos usando uma lista padrão de stopwords para a lingua portuguesa, mas existe a possibilidade de incluirmos outras palavras que queremos eliminar no contexto desse sistema de recomendação, tendo assim uma lista de palavras mais customizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Caso Bruno e Dom: 3º suspeito tem prisão temporária decretada pela Justiça do AM\n",
      "Tags: decretada temporária 3º\n",
      "\n",
      "Texto: Linguajar dos santarenos é diferenciado e cheio de identidade; 'égua, tu não vai\n",
      "Tags: leso linguajar santarenos\n",
      "\n",
      "Texto: Ex-premiê Shinzo Abe morre após ser baleado no Japão\n",
      "Tags: shinzo abe premiê\n",
      "\n",
      "Texto: Relator no STF, Fachin vota contra marco temporal para demarcação de terras indí\n",
      "Tags: demarcação vota relator\n",
      "\n",
      "Texto: \n",
      "Após 2 votos, pedido de vista suspende julgamento no STF sobre demarcação de te\n",
      "Tags: demarcação terras julgamento\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste_tags('title', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado das tags para o titulo é mediano. Esse é um resultado esperado, uma vez que o modelo está rodando basicamente em configurações padrão e os textos dos titulos geralmente são curtos.\n",
    "\n",
    "O resultado, em uma primeira análise, não parece ter uma qualidade muito alta, mas acredito que pode ser aproveitado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Jeferson da Silva Lima foi escoltado por agentes da Polícia Federal ao Fórum de \n",
      "Tags: escoltado jeferson custódia fórum audiência lima agentes silva município justiça federal polícia\n",
      "\n",
      "Texto: As expressões santarenas não significam apenas o “sim” ou “não”, inclusive às ve\n",
      "Tags: significam expressões santarenas pérola tapajós palavras coisas sim usadas inclusive vezes apenas\n",
      "\n",
      "Texto: Ex-primeiro-ministro foi atingido por tiros de espingarda caseira quando discurs\n",
      "Tags: discursava rígido nara raros caseira similares chocou espingarda japão armas controle atingido\n",
      "\n",
      "Texto: Ministro defendeu que posse indígena é diferente da posse civil porque Constitui\n",
      "Tags: demarcações parâmetro originário definirá posse defendeu constituição diferente garante terras indígena usado\n",
      "\n",
      "Texto: Pelo marco temporal, índios só podem reivindicar demarcação de terras já ocupada\n",
      "Tags: reivindicar demarcação 1988 ocupadas votou índios fachin edson constituição temporal marco relator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste_tags('caption', 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O caption é um pouco mais detalhado e informativo, esse texto permite a extração de mais tags e provavelmente elas serão de ais qualidade. Ainda percebo ruídos nas tags, mas acredito que o resultado pode ser usado para encontrar uma correlação entre as matérias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Após audiência de custódia, a Justiça do Amazonas decretou, na tarde deste sábad\n",
      "Tags: phillips jeferson dom bruno pereira pelado indigenista dinha temporária amazonas prisão javari mortais amazônia restos embarcação oseney justiça jornalista decretou confirma lima custódia aras amarildo\n",
      "\n",
      "Texto: Vista aérea de Santarém\n",
      "Ádrio Denner/ AD Produções\n",
      "O paraense tem um vocabulário\n",
      "Tags: égua santarém santarenos expressões santareno indivíduo olha expressa figarella expressão intimidade denner jana descrença pará alguém significados vocabulário algo modo negação falar dúvida conjunção significam\n",
      "\n",
      "Texto: Novo vídeo mostra que assassino de Shinzo Abe atirou 2 vezes pelas costas.\n",
      "O ex-\n",
      "Tags: abe shinzo japão premiê japonês ex ministro kyodo abenomics primeiro kishida nhk morte baleado poder reuters mesclava exterior país detido imperdoável cargo fumio atentado reformas\n",
      "\n",
      "Texto: Relator no STF, Fachin vota contra marco temporal para demarcação de terras indí\n",
      "Tags: indígenas temporal demarcação terras marco stf fachin indígena tese constituição índios critério demarcações posse jurídica ministro relator raposa existência supremo trf decisão funai terra direitos\n",
      "\n",
      "Texto: Após um pedido de vista (mais tempo para análise do processo) do ministro Alexan\n",
      "Tags: temporal marco indígenas demarcação stf terras tese julgamento indígena critério marques pedido supremo trf decisão funai fachin julgar brasília contra ministro favorável vista julgado entendimento\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste_tags('body')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O corpo da matéria, por ser mais informativo e conter uma quantidade maior de texto,é esperado que tenhamos uma quantidade maior de tags relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O TfidfVectorizer está trazendo resultados interessantes, mas o chat gpt está sugerindo o keybert como uma opção com melhores resultados em testes de benchmark. Sendo assim, vou testar essa segunda biblioteca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\urllib3\\contrib\\socks.py:50: DependencyWarning: SOCKS support in urllib3 requires the installation of optional dependencies: specifically, PySocks.  For more information, see https://urllib3.readthedocs.io/en/latest/advanced-usage.html#socks-proxies\n",
      "  warnings.warn(\n",
      "c:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Após audiência de custódia, a Justiça do Amazonas decretou, na tarde deste sábad\n",
      "Tags: pelado prisão dinha mandado escoltado ocultação munição atividade prorrogado correção identificação peritos participação detidos segundo considerado lima cabeça embarcação momento relação feira foragido pede parecido\n",
      "\n",
      "Texto: Vista aérea de Santarém\n",
      "Ádrio Denner/ AD Produções\n",
      "O paraense tem um vocabulário\n",
      "Tags: diferenciado negação felicidade estudos informação estado identidade carinhoso linguístico realidade funcionam satisfação função santareno junção curiosidades santarenos descontentamento entonação significa característico conjunção devido égua produções\n",
      "\n",
      "Texto: Novo vídeo mostra que assassino de Shinzo Abe atirou 2 vezes pelas costas.\n",
      "O ex-\n",
      "Tags: assassino significa shinzo estação realmente necessidade segundo desejo mencionava informação fabricação coração desempregado identificado atentado momento oito eleição popularidade ano legado caseira enforcamento atacado nacionalismo\n",
      "\n",
      "Texto: Relator no STF, Fachin vota contra marco temporal para demarcação de terras indí\n",
      "Tags: terra terras posicionamento situação existência julgamento congresso acampamento critério complexidade fachin miserabilidade índios temporal segundo cerca identidade julgado relação significa constituição garantem constitucionais aplicação demarcação\n",
      "\n",
      "Texto: Após um pedido de vista (mais tempo para análise do processo) do ministro Alexan\n",
      "Tags: julgamento julgado acampamento aplicação adiamento congresso manifestou apresentou proteção promulgação brasileira demarcação região podem segundo advogado processo frente critério argumentou porque pedido abaixo aplicado sendo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "\n",
    "for texto in df_itens['body'][:5]:\n",
    "    keywords = kw_model.extract_keywords(texto, keyphrase_ngram_range=(1,1), stop_words=pt_stopwords, top_n=25)\n",
    "    print(f\"Texto: {texto[:80]}\")\n",
    "    print(f\"Tags: {' '.join([ kw[0] for kw in keywords ])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em minha impressão inicial, o resultado do keybert não é muito melhor que o do TfidfVectorizer (se não for pior). Quero fazer uns testes com clusterização para comparar os resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def get_stopwords(language:str):\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    return list(stopwords.words(language))\n",
    "\n",
    "\n",
    "def test_clusters(df, feature:str, n_clusters:int=10, n_components:int=10, chunk_size:int=10):\n",
    "    df = df.copy()\n",
    "\n",
    "    pt_stopwords = get_stopwords('portuguese')\n",
    "    vectorizer = TfidfVectorizer(stop_words=pt_stopwords)\n",
    "    pca = IncrementalPCA(n_components=n_components)\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=64)\n",
    "\n",
    "    X = vectorizer.fit_transform(df[feature])\n",
    "    for chunk in range(0, X.shape[0], chunk_size):\n",
    "        pca.partial_fit(X[chunk:chunk+chunk_size].toarray())\n",
    "        kmeans.partial_fit(pca.transform(X[chunk:chunk+chunk_size].toarray()))\n",
    "    \n",
    "    df['cluster'] = kmeans.predict(df[feature])\n",
    "    \n",
    "    score = silhouette_score(X, df['cluster'])\n",
    "    print(f\"Silhouette Score: {score}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 711. MiB for an array with shape (1000, 93236) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_itens_clustered \u001b[38;5;241m=\u001b[39m \u001b[43mtest_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_itens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcaption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 26\u001b[0m, in \u001b[0;36mtest_clusters\u001b[1;34m(df, feature, n_clusters, n_components, chunk_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m X \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(df[feature])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], chunk_size):\n\u001b[1;32m---> 26\u001b[0m     pca\u001b[38;5;241m.\u001b[39mpartial_fit(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     27\u001b[0m     kmeans\u001b[38;5;241m.\u001b[39mpartial_fit(pca\u001b[38;5;241m.\u001b[39mtransform(X[chunk:chunk\u001b[38;5;241m+\u001b[39mchunk_size]\u001b[38;5;241m.\u001b[39mtoarray()))\n\u001b[0;32m     29\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mpredict(df[feature])\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1170\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1170\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\scipy\\sparse\\_base.py:1366\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 711. MiB for an array with shape (1000, 93236) and data type float64"
     ]
    }
   ],
   "source": [
    "df_itens_clustered = test_clusters(df_itens, 'caption', 25, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.01026533855804245\n"
     ]
    }
   ],
   "source": [
    "df_itens_clustered = test_clusters(df_itens, 'caption', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.0127077048271191\n"
     ]
    }
   ],
   "source": [
    "df_itens_clustered = test_clusters(df_itens, 'caption', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.47 GiB for an array with shape (5000, 93236) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_itens_clustered \u001b[38;5;241m=\u001b[39m \u001b[43mtest_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_itens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcaption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 29\u001b[0m, in \u001b[0;36mtest_clusters\u001b[1;34m(df, feature, n_clusters)\u001b[0m\n\u001b[0;32m     26\u001b[0m pt_stopwords \u001b[38;5;241m=\u001b[39m get_stopwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportuguese\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m get_pipeline(pt_stopwords, n_clusters)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(df[feature])\n\u001b[0;32m     33\u001b[0m score \u001b[38;5;241m=\u001b[39m silhouette_score(pipeline[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(df[feature]), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:660\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    655\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    656\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    657\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    658\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    659\u001b[0m         )\n\u001b[1;32m--> 660\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1502\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[1;32m-> 1502\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1518\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[0;32m   1520\u001b[0m ):\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:165\u001b[0m, in \u001b[0;36m_threadpool_controller_decorator.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m controller \u001b[38;5;241m=\u001b[39m _get_threadpool_controller()\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:684\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[1;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;66;03m# Buffers to avoid new allocations at each iteration.\u001b[39;00m\n\u001b[0;32m    683\u001b[0m centers \u001b[38;5;241m=\u001b[39m centers_init\n\u001b[1;32m--> 684\u001b[0m centers_new \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    685\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m    686\u001b[0m labels_old \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\projects\\fiap-1mlet\\Projeto_5_Datathon\\.venv\\Lib\\site-packages\\numpy\\_core\\numeric.py:128\u001b[0m, in \u001b[0;36mzeros_like\u001b[1;34m(a, dtype, order, subok, shape, device)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_zeros_like_dispatcher)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mzeros_like\u001b[39m(\n\u001b[0;32m     66\u001b[0m     a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     67\u001b[0m ):\n\u001b[0;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    Return an array of zeros with the same shape and type as a given array.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mempty_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# needed instead of a 0 to get same result as zeros for string dtypes\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     z \u001b[38;5;241m=\u001b[39m zeros(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.47 GiB for an array with shape (5000, 93236) and data type float64"
     ]
    }
   ],
   "source": [
    "df_itens_clustered = test_clusters(df_itens, 'caption', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
